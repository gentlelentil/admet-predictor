{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the molecular properties of the input molecules using the RDKit, using only the properties used in the model.\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from rdkit.Chem.rdmolops import SanitizeFlags\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_calc = MolecularDescriptorCalculator([x for x in [x[0] for x in Descriptors.descList]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_directory = ['oral_abs_class',\n",
    " 'hia_class',\n",
    " 'crl_toxicity_class',\n",
    " 'ML_input_p450-cyp3a4',\n",
    " 'ames_mutagenicity_class',\n",
    " 'ML_input_p450-cyp2c19',\n",
    " 'hep_g2_toxicity_class',\n",
    " 'nih_toxicity_class',\n",
    " 'herg_blockers_class',\n",
    " 'hek_toxicity_class',\n",
    " 'hacat_toxicity_class',\n",
    " 'ML_input_p450-cyp1a2',\n",
    " 'bbb_class',\n",
    " 'ML_input_p450-cyp2d6',\n",
    " 'ML_input_p450-cyp2c9',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Invalid SMILES: {smiles}\")\n",
    "    \n",
    "    # Calculate molecular descriptors\n",
    "    descriptor = np.array(desc_calc.CalcDescriptors(mol)).reshape(1, -1)\n",
    "    descriptor[np.isinf(descriptor)] = np.nan  # Replace infinite values with NaN\n",
    "\n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_new_molecule(smiles, imputer, scaler, selected_features):\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     if mol is None:\n",
    "#         raise ValueError(f\"Invalid SMILES: {smiles}\")\n",
    "    \n",
    "#     # Calculate molecular descriptors\n",
    "#     descriptor = np.array(desc_calc.CalcDescriptors(mol)).reshape(1, -1)\n",
    "#     descriptor[np.isinf(descriptor)] = np.nan  # Replace infinite values with NaN\n",
    "\n",
    "#     # Impute missing values\n",
    "#     descriptor = imputer.transform(descriptor)\n",
    "\n",
    "#     # Scale the descriptors\n",
    "#     descriptor = scaler.transform(descriptor)\n",
    "\n",
    "#     # Select features based on variance threshold\n",
    "#     descriptor = descriptor[:, selected_features]\n",
    "\n",
    "#     return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_descriptors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = \"C1=CC=CC=C1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing oral_abs_class\n",
      "Processing hia_class\n",
      "Processing crl_toxicity_class\n",
      "Processing ML_input_p450-cyp3a4\n",
      "Processing ames_mutagenicity_class\n",
      "Processing ML_input_p450-cyp2c19\n",
      "Processing hep_g2_toxicity_class\n",
      "Processing nih_toxicity_class\n",
      "Processing herg_blockers_class\n",
      "Processing hek_toxicity_class\n",
      "Processing hacat_toxicity_class\n",
      "Processing ML_input_p450-cyp1a2\n",
      "Processing bbb_class\n",
      "Processing ML_input_p450-cyp2d6\n",
      "Processing ML_input_p450-cyp2c9\n"
     ]
    }
   ],
   "source": [
    "for csv_name in csv_directory:\n",
    "    print(f\"Processing {csv_name}\")\n",
    "    \n",
    "    # load the preprocessing objects\n",
    "    imputer = joblib.load(f\"data/{csv_name}/{csv_name}_imputer.pkl\")\n",
    "    scaler = joblib.load(f\"data/{csv_name}/{csv_name}_scaler.pkl\")\n",
    "    selected_features = joblib.load(f\"data/{csv_name}/{csv_name}_selected_features.pkl\")\n",
    "    variance_threshold = joblib.load(f\"data/{csv_name}/{csv_name}_variance_threshold.pkl\")\n",
    "\n",
    "\n",
    "    descriptor = smiles_to_descriptors(smiles)\n",
    "\n",
    "    descriptor = imputer.transform(descriptor)\n",
    "\n",
    "    descriptor = scaler.transform(descriptor)\n",
    "\n",
    "    descriptor = descriptor[:, selected_features]  # Select by the saved indices  \n",
    "\n",
    "    \n",
    "    mol_descriptors.append(descriptor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsmiles = 'CC1=CC(=C(C=C1)C(=O)O)O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(smiles):\n",
    "    results = {}\n",
    "\n",
    "    for csv_name in csv_directory:\n",
    "        try:\n",
    "            # Load the preprocessing objects and model for each dataset\n",
    "            imputer = joblib.load(f'./data/{csv_name}/{csv_name}_class_imputer.pkl')\n",
    "            scaler = joblib.load(f'./data/{csv_name}/{csv_name}_class_scaler.pkl')\n",
    "            selected_features = joblib.load(f'./data/{csv_name}/{csv_name}_class_selected_features.pkl')\n",
    "            \n",
    "            # model = joblib.load(f'./data/{csv_name}/{csv_name}_model.pkl')  # Assuming the trained model is saved here\n",
    "\n",
    "            # Preprocess the new SMILES\n",
    "            descriptors = preprocess_new_molecule(smiles, imputer, scaler, selected_features)\n",
    "\n",
    "            # Make the prediction\n",
    "            # prediction = model.predict(descriptors)\n",
    "\n",
    "            # Store the result\n",
    "    #         results[csv_name] = prediction[0]  # Assuming the model returns an array\n",
    "    #     except Exception as e:\n",
    "    #         # Handle any errors that occur during prediction\n",
    "    #         results[csv_name] = f\"Error: {str(e)}\"\n",
    "\n",
    "    # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLinear_3L\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,input_dim, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m         \u001b[39msuper\u001b[39m(Linear_3L, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class Linear_3L(torch.nn.Module):\n",
    "    def __init__(self,input_dim, *args, **kwargs) -> None:\n",
    "        super(Linear_3L, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.Lin0 = torch.nn.Linear(input_dim, 2000)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(2000)\n",
    "        self.dropout = torch.nn.Dropout(0.75)\n",
    "\n",
    "        self.Lin1 = torch.nn.Linear(2000, 500)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(500)\n",
    "        self.Lin2 = torch.nn.Linear(500, 10)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm1d(10)\n",
    "\n",
    "        self.linout = Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = data.x\n",
    "\n",
    "        #L1\n",
    "        out = F.relu(self.Lin0(x))\n",
    "        out = F.relu(self.batchnorm1(out))\n",
    "        out = self.dropout(out)\n",
    "        # print('L1')\n",
    "\n",
    "        out = F.relu(self.Lin1(out))\n",
    "        out = F.relu(self.batchnorm2(out))\n",
    "        out = self.dropout(out)\n",
    "        # print('L2')\n",
    "\n",
    "        out = F.relu(self.Lin2(out))\n",
    "        out = F.relu(self.batchnorm3(out))\n",
    "        out = self.dropout(out)\n",
    "        # print('L3')\n",
    "\n",
    "        out = torch.sigmoid(self.linout(out))\n",
    "        out = out.view(-1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imputer \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{\u001b[39;00mcsv_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcsv_name\u001b[39m}\u001b[39;00m\u001b[39m_imputer.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m scaler \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{\u001b[39;00mcsv_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcsv_name\u001b[39m}\u001b[39;00m\u001b[39m_scaler.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m selected_features \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{\u001b[39;00mcsv_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcsv_name\u001b[39m}\u001b[39;00m\u001b[39m_selected_features.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_name' is not defined"
     ]
    }
   ],
   "source": [
    "imputer = joblib.load(f'./data/{csv_name}/{csv_name}_imputer.pkl')\n",
    "scaler = joblib.load(f'./data/{csv_name}/{csv_name}_scaler.pkl')\n",
    "selected_features = joblib.load(f'./data/{csv_name}/{csv_name}_selected_features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
